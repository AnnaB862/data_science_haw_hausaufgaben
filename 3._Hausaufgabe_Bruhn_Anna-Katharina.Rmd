---
title: "3. Hausaufgabe Bruhn, Anna-Katharina"
output: html_notebook
---

Library laden

```{r}
library(tidyverse)
```

## Alle Datensätze importieren und zu einem Datensatz "books_ratings_users" verbinden

```{r}
library(readr)
books <- read_delim("BX-Books.csv", 
    ";", escape_backslash = TRUE, escape_double = FALSE, 
    trim_ws = TRUE)
```

```{r}
library(readr)
book_ratings <- read_delim("BX-Book-Ratings.csv", 
    ";", escape_double = FALSE, trim_ws = TRUE)
View(book_ratings)
```

```{r}
library(readr)
users <- read_delim("BX-Users.csv", 
    ";", escape_double = FALSE, trim_ws = TRUE)
View(users)
```

## Data cleaning

```{r}
users <- users %>%
  mutate(Age = as.numeric(Age)) %>%
  mutate(Location = str_remove(Location,".*,")) 
  
```

Um die Location einheitlicher zu gestallten und verschiedene Schreibweisen eines Ortes zu vermeiden wird es auf die Nennung des Landes beschränkt.

```{r}
users <- users %>% 
  mutate(Age = replace(Age, which(Age>99), NA)) %>%
  mutate(Age = replace(Age, which(Age<6), NA))
```

Unmögliche und sehr unwahrscheiliche Altersangabe wird durch NA ersetzt. Die Altersangabe wird auf einen Wert zwischen 6 bis 99 Jahre alt beschränkt.

```{r}
book_ratings$`Book-Rating`[book_ratings$`Book-Rating` == 0] <- NA
```

Die Bewertung von Büchern ist mit einem Wert von 1-10 angegeben, 0 bedeutet hier, dass keine Bewertung abgegeben worden ist, also ersetze ich das durch NA.

```{r}
books$`Year-Of-Publication`[books$`Year-Of-Publication` == 0] <- NA
```

Alle Einträge mit der Angabe 0 bei dem Erscheinungsjahr ersetze ich mit NA, da 0 mit großer Wahrscheinlichkeit keine zutreffende Angabe ist.

```{r}
books$`Year-Of-Publication`[books$`Year-Of-Publication` >= 2004] <- NA
```

Die User konnten bis 2004 Bücher bewerten, der Datensatz wurde zu dem Zeitpunkt erstellt. Also sind alle Erscheinungsdaten die größer als 2004 sind falsch und werden durch NA ersetzt.

```{r}
books <- books %>%
  mutate(`Book-Author` = str_to_lower(`Book-Author`)) %>%
  mutate(`Book-Title` = str_to_lower(`Book-Title`)) %>%
  mutate(Publisher = str_to_lower(Publisher)) %>%
  mutate(`Book-Author` = str_replace(`Book-Author`,"ç","c")) %>%
  mutate(`Book-Title` = str_replace(`Book-Title`,"ç","c")) %>%
  mutate(`Publisher` = str_replace(`Publisher`,"ç","c")) %>%
  mutate(`Book-Author` = str_replace(`Book-Author`,"ñ","n")) %>%
  mutate(`Book-Title` = str_replace(`Book-Title`,"ñ","n")) %>%
  mutate(`Publisher` = str_replace(`Publisher`,"ñ","n")) %>%
  mutate(`Book-Author` = str_replace(`Book-Author`,"è","e")) %>%
  mutate(`Book-Title` = str_replace(`Book-Title`,"è","e")) %>%
  mutate(`Publisher` = str_replace(`Publisher`,"è","e")) %>%
  mutate(`Book-Author` = str_replace(`Book-Author`,"é","e")) %>%
  mutate(`Book-Title` = str_replace(`Book-Title`,"é","e")) %>%
  mutate(`Publisher` = str_replace(`Publisher`,"é","e")) %>%
  mutate(`Book-Author` = str_replace(`Book-Author`,"ê","e")) %>%
  mutate(`Book-Title` = str_replace(`Book-Title`,"ê","e")) %>%
  mutate(`Publisher` = str_replace(`Publisher`,"ê","e")) %>%
   mutate(`Book-Author` = str_replace(`Book-Author`,"ô","o")) %>%
  mutate(`Book-Title` = str_replace(`Book-Title`,"ô","o")) %>%
  mutate(`Publisher` = str_replace(`Publisher`,"ô","o")) %>% 
   mutate(`Book-Author` = str_replace(`Book-Author`,"à","a")) %>%
  mutate(`Book-Title` = str_replace(`Book-Title`,"à","a")) %>%
  mutate(`Publisher` = str_replace(`Publisher`,"à","a")) 
```

Im Datensatz werden ale Titel und Autoren klein geschrieben und Sonderzeichen werden entfernt.

```{r}
books_w_ratings <- books %>%
  select(ISBN, `Book-Title`, `Book-Author`, `Year-Of-Publication`, Publisher) %>%
  left_join(book_ratings)
```

## Der neu erstellter Datensatz "book_rating_users"

```{r}
books_ratings_users <- books_w_ratings %>%
  left_join(users)
```

```{r}
books_ratings_users <- books_ratings_users %>%
  mutate(ISBN = str_extract(ISBN, "[0-9]*X*"))
```

Der neu erstellte Datensatz "book_rating_users" wird als csv-Datei gespeichert, damit man mit dem Datensatz weiterarbeiten kann, ohne ihn jedesmal neu erstellen zu müssen.


# Association Rules - Der apriori-Algorithmus
## Aufgaben

Library laden

```{r}
library(arules)
```


```{r massage=FALSE}
i <- split(books_ratings_users$`Book-Title`, books_ratings_users$`User-ID`)
txn <- as(i, "transactions")
trans.rules <- apriori(txn, parameter=list(supp=0.0015, conf=0.5, minlen=2, target="rules"))
```
```{r}

head(inspect(subset(trans.rules)), 10)
```
```{r}
subrules <- head(trans.rules, n = 15, by = "lift")
```

```{r}
library(arulesViz)
plot(subrules, method = "graph")
```

In dem Plot sieht man, dass gerade einzelne Bände einer Reihe eine starke Assoziation haben. Das heißt, dass User die ein Buch einer Reihe, wie "Herr der Ringe" oder "Harry Potter" bewertet haben, haben auch andere Bände der Reihe bewertet. Der Support ist bei den Harry Potter Bänden am größten, der Lift ist bei späteren Bänden einer Reihe höher als beim ersten oder zweiten Band der Reihe. Die Assoziation der "Herr der Ringe" Bände ist größer als bei "Harry Potter". Der Hohe Support der "Harry Potter" Bände deutet auf eine viel größere Leserschaft dieser Reihe hin als bei "Herr der Ringe".
Das es zwischen einzelnen Bänden einer Reihe eine Assoziation zueinander gibt, ist zu erwarten gewesen.

## Spielen Sie mit den Support- und Confidence-Werten. Was fällt Ihnen auf?

```{r massage=FALSE}
i <- split(books_ratings_users$`Book-Title`, books_ratings_users$`User-ID`)
txn <- as(i, "transactions")
trans.rules <- apriori(txn, parameter=list(supp=0.1, conf=0.001, minlen=2, target="rules"))
```

```{r}

head(inspect(subset(trans.rules)), 10)
```
```{r massage=FALSE}
i <- split(books_ratings_users$`Book-Title`, books_ratings_users$`User-ID`)
txn <- as(i, "transactions")
trans.rules <- apriori(txn, parameter=list(supp=0.01, conf=0.001, minlen=2, target="rules"))
```

```{r}

head(inspect(subset(trans.rules)), 10)
```
Bei einem Support mit einer oder zwei Nachkommastellen werden keine Sets gefunden, erst bei einer dreistelligen Nachkommastelle gibt es Ergebnisse. Das bedeutet, dass es sehr viele einzelne Bewertungen von Usern gibt, da der Support die Anzahl der Transaktionen mit dieser Item-Kombination geteilt durch alle Transaktionen, ungeachtet dessen, ob weitere Items in der Transaktion waren, ist.

Die Confidence ist der Support für das gleichzeitige Auftreten aller Items in einer Regel, bedingt nur durch den Support für das Left-hand Set. Das Ergebnis ist die Assotiation, die allerdings noch keine Kausalität bedeutet. Eingeordnet wird dies durch den Lift. Der Lift gibt an wie viel häufiger ein Set auftaucht, als wir erwarten würden, wenn die Items unabhängig voneinander wären. 

Die Confidence beginnt schon bei der ersten Nachkommastelle, also gibt es einige Sets mit einer hohen Assoziation. Wenn man den Confidence - Wert verändert, wird mal mehr, mal weniger angezeigt, je nach dem wie viele Sets die Bedingung erfüllen. Da man keine sehr lange Liste haben will werden nur Sets mit 0.5 oder 50% Assoziation angezeigt.

## Wir haben jetzt alle Bewertungen drin, ergibt das Sinn? 

Alle von Usern bewertete Bücher sind im Datensatz enthalten, daher ist der Support niedrig. Grund hierfür ist, dass durch die Menge an wenig bewerteten Büchern mit einer geringen Assoziation den Support niedrig machen. 
Der Support ist die Anzahl der User-Bewertungen mit diesen "Book-Title"-Kombination geteilt durch alle User-Bewertung, uabhängig davon, ob  der User weitere "Book-Title" bewertet hat.
Da hier nur Sets mit einer hohen Assoziation (abgebildet in der Condidence und im Lift), interessieren, können Bücher die nur wenige Bewertungen haben weggelassen werden, da sie den Support verzerren.

## Wie könnte eine bessere Lösung aussehen?
    
```{r}
books_ratings_users1 <- books_ratings_users %>%
  group_by(`Book-Title`) %>%
  mutate(anzahl_bewertungen = n()) %>%
  filter(anzahl_bewertungen > 10) %>%
  select(`User-ID`, `Book-Title`, `Book-Author`, `Book-Rating`) %>%
  ungroup()
```

```{r massage=FALSE}
i <- split(books_ratings_users1$`Book-Title`, books_ratings_users1$`User-ID`)
txn <- as(i, "transactions")
trans.rules <- apriori(txn, parameter=list(supp=0.002, conf=0.5, minlen=2, target="rules"))
```  

```{r}

head(inspect(subset(trans.rules)), 10)
```
```{r}
subrules <- head(trans.rules, n = 15, by = "lift")
```

```{r}
library(arulesViz)
plot(subrules, method = "graph")
```
Nach der beseitigung der User mit weniger als 10 Bewertungen sind immer noch Reihen mit der größten Assoziation, jedoch ist der Support gestiegen. 


# Erstellen Sie eine Analyse, bei der nicht die Bücher, sondern die Autoren in den Transaktionen enthalten sind

```{r massage=FALSE}
i <- split(books_ratings_users1$`Book-Author`, books_ratings_users1$`User-ID`)
txn <- as(i, "transactions")
trans.rules <- apriori(txn, parameter=list(supp=0.006, conf=0.6, minlen=2, target="rules"))
```

```{r}
head(inspect(subset(trans.rules)), 10)
```     

```{r}
subrules <- head(trans.rules, n = 15, by = "lift")
```

```{r}
library(arulesViz)
plot(subrules, method = "graph")
```


# Fällt Ihnen etwas in der Datenqualität auf?

Da manche Autoren zwei Vornamen haben, oder der Vorname mal abgekürzt angegeben wurde und mal nicht, kommt es vor, dass in einem Set eine Assoziation eines Autors mit sich selbst in anderer Schreibweise hergestellt wird. Allerdings kann man nicht gänzlich ausschließen, dass es nicht tatsächlich zwei unterschiedliche Menschen sind mit einem sehr ähnlichen Namen.Dies muss also zunächst behoben werden, bevor man weiter mit dem Datensatz arbeitet.

# Wie könnte man das mit regulären Ausdrücken beheben?

Die verschiedenen Schreibweisen führen dazu, dass Bewertungen von Usern zu einem Autor, bei unterschiedlicher Schreibweise, nebeneinander auftauchen und nicht unter einem Namen gesammelt werden. Meine Ideen dies zu Lösen sind in den folgenden vier Ideen aufgelistet.

Umgesetzt habe ich nur Idee 3 und 4. 
Die Ideen 1 und 2 sind nicht praktikabel, da hier die Gefahr der Namensdopplung noch zu hoch ist.

## Ideen

1. Nur Nachnamen 

Nur die Nachnamen zu nutzen wäre eine Lösung, aber dies würde die Gefahr erhöhen, verschiedene Autoren mit dem gleichen Nachnamen als ein Autor zu zählen. Daher ist diese Idee nicht zielführend.

2. Abkürzung der Vornamen

Bei Abkürzung der Vornamen ist die klarere Zuordnung von Autoren eher gegeben, als nur bei Nachnamen. Es würde auch eine einheitliche Regel für Abkürzungen bedingen. Aber es besteht immer noch die Gefahr das zwei Autoren den selben Namen haben.

3. Nur erster Vorname und der Nachname

Wenn nur der erste Vorname und der Nachname genommen wird, ist es nicht ganz so uneindeutig, wie nur die Initialien des Vornamens zu verwenden. Es werden außerdem die unterschiedlich gesetzten Leerzeichen zwischen den Initialien beseitigt, da es nur ein Leerzeichen zwischen Vorname und Nachname gibt.

4. Mauel alle Namensdoppelungen beheben

Diese Lösung ist eigentlich ungeeignet, da man bei einem sehr großen Datensatz sehr viel Zeit aufwenden müsste. Aber es würde Restfehler, die bei den anderen Lösungen da wären beheben. 
Effizienter und praktikabler ist jedoch Lösung 3.

## Umzusetzungen der Ideen

3. Nur erster Vorname und der Nachname

```{r}
books_ratings_users2 <- books_ratings_users1 %>%
  mutate(`Book-Author` = str_replace_all(`Book-Author`, " .* ", " "))
```

```{r massage=FALSE}
i <- split(books_ratings_users2$`Book-Author`, books_ratings_users2$`User-ID`)
txn <- as(i, "transactions")
trans.rules <- apriori(txn, parameter=list(supp=0.006, conf=0.5, minlen=2, target="rules"))
```

```{r}
head(inspect(subset(trans.rules)), 10)
```    
```{r}
subrules <- head(trans.rules, n = 15, by = "lift")
```

```{r}
library(arulesViz)
plot(subrules, method = "graph")
```
Hier hat man nun die Autoren mit der höchsten Assoziation aufgeführt, nach beseitigung der Namensdoppelung.


4. Mauel alle Namensdoppelungen beheben (eher unpraktisch)

Hier habe ich nicht den ganzen Datensatz bearbeitet, ich habe lediglich die Autoren die doppelt mit einer hohen Assoziation erschienen, angeglichen. Es besteht somit aber das Problem, das Autoren, die nun unter verschiedenen Schreibweisen aufgeführt werden, nicht bei den Autoren mit einer hohen Assoziation auftauen, obwohl sie es möglicherweise bei einer Zusammenführung der Schreibweisen würden, nicht angepasst werden.

```{r}
books_ratings_users3 <- books_ratings_users1 %>%
  mutate(`Book-Author` = str_replace(`Book-Author`,"tim f. lahaye","tim lahaye")) %>%
  mutate(`Book-Author` = str_replace(`Book-Author`,"r. l. stine","r.l. stine")) %>%
  mutate(`Book-Author` = str_replace(`Book-Author`,"patricia daniels cornwell","patricia d. cornwell")) 
```
```{r massage=FALSE}
i <- split(books_ratings_users3$`Book-Author`, books_ratings_users3$`User-ID`)
txn <- as(i, "transactions")
trans.rules <- apriori(txn, parameter=list(supp=0.007, conf=0.5, minlen=2, target="rules"))
```
```{r}
head(inspect(subset(trans.rules)), 10)
```    
## Wie kann man nun noch sicherstellen, dass nur die Autoren weiterempfohlen werden, deren Bücher man auch (mehrheitlich) gut fand?

Es gibt zwei Möglichkeiten, wie man dies bestimmen könnte, indem man die Durchschnittsbewertung der Authoren berechnet und dies als Grundlage zur Darstellung der Assoziations-Regeln nimmt oder alle Bewertungen die schlechter als 7 sind weglässt und die Assoziations-Regeln berechnet, so sind alle niedrigen Bewerungen nicht mehr Teil der Darstellung.

1. Möglichkeit: 

```{r}
durchschnitt_ratings <- books_ratings_users2 %>%
  group_by(`Book-Author`) %>%
  select(`User-ID`, `Book-Title`, `Book-Author`, `Book-Rating`) %>%
  drop_na(`Book-Rating`) %>% 
  summarize(durchschnittsbewertung = mean(`Book-Rating`), anzahl_bewertungen = n (),`User-ID`) %>%
  filter(anzahl_bewertungen >= 10) %>%
  arrange(desc(durchschnittsbewertung)) %>%
  ungroup()
```

Zunächst wird die Durchschnittsbewertung ermittelt, um sicherzustellen, dass nur die Bücher weiterempfolen werden, die mehrheitlich gut gefunden werden. 

```{r massage=FALSE}
i <- split(durchschnitt_ratings$`Book-Author`, durchschnitt_ratings$`User-ID`)
txn <- as(i, "transactions")
trans.rules <- apriori(txn, parameter=list(supp=0.0018, conf=0.05, minlen=2, target="rules"))
```    
```{r}
head(inspect(subset(trans.rules)), 10)
```     
In der oberen Liste werden die Assoziationsregeln angezeigt, die auf Grundlage der Durchschnittsbewertung der Autoren durch User ermittelt wurden. 

```{r}
subrules <- head(trans.rules, n = 15, by = "lift")
```

```{r}
library(arulesViz)
plot(subrules, method = "graph")
```
In der oberen Grafik sind die Autoren abgebildet, die mehrheitlich von den Usern gut bewertet wurden und deren Assoziation zueinander. 
Es gibt zwei Komplexe,einen großen, bei dem stephen king und dean koontz in der Mitte sind und zu john grisham, patricia cornwell und james patterson und anderen eine Assoziation haben. Die Kreise sind relativ groß, sie haben also einen recht großen Support aber einen unterschiedlich großen Lift, da die Kreise eine leicht rosa Färbung und einige auch pink sind. Der zweite Komplex besteht aus zwei Autoren die einen niedrigen Support aber einen recht hohen Lift haben.

2. Möglichkeit, man entfernt die Book-Ratings mit weniger als 7, jetzt wären nur noch die hohen Raitings übrig. 

Jedoch ist Lösung 1, den Duchschnitt zu errechnen um, zu Ermitteln welche Autoren mehrheitlich gut gefunden wurden, die bessere Lösung. Hier werden nämlich auch die schlechten Bewertungen mit einbezogen, die bei der 2. Möglichkeit nicht gewertet werden würde, aber bei einer mehrheitlichen Bewertung mit einbezogen werden muss.

```{r}
moeglichkeit_2 <- books_ratings_users2 %>%
  filter(`Book-Rating` > 7)
```

```{r massage=FALSE}
i <- split(moeglichkeit_2$`Book-Author`, moeglichkeit_2$`User-ID`)
txn <- as(i, "transactions")
trans.rules <- apriori(txn, parameter=list(supp=0.0018, conf=0.1, minlen=2, target="rules"))
```  

```{r}
head(inspect(subset(trans.rules)), 10)
```     
```{r}
subrules <- head(trans.rules, n = 15, by = "lift")
```

```{r}
library(arulesViz)
plot(subrules, method = "graph")
```
Das Ergebnis ist nun sehr unterschiedlich zur ersten Möglichkeit. ES bestehen weniger Assoziationen untereinander, die Autoren sind aufgesplitterter. 

Im Ergebis ist diese Lösung nicht geeignet, da sie die eher schlechten Bewertungen der User nicht mit in die Assoziations-Regeln der Autoren berücksichtigt werden. Aber wenn man die mehrheitlich gut gefundenen Autoren ermitteln möchte, ist jede Bewertung aller User, ab einer bestimmten Bewertungsanzahl eines Users wichtig, besonders auch die schlechten Bewertungen.

## Welche anderen Features wären sinnvoll?

Es gibt weitere zahlreiche Möglichkeiten den Datensatz mit unterschiedlichen Fragestellung auf starke Assoziation zu untersuchen, je nach den Interessen des Fragestellers. 

So könnte man untersuchen wer in einem bestimmten Land welche Autoren oder Titel gut findet. Man kann außerdem die Unterschiede zwischen den Ländern ermitteln. So könnte man auf die Besonderheiten der regionalen Unterschiede eingehen und zum Beispiel eine Marketing- Strategie hieraus entwickeln.

Der Datensatz kann nach Alltersgruppe untersucht werden, bei welche Altersgruppe eine Assoziation zwischen welchen Büchern oder Autoren besteht. 

Interessant wäre auch zu untersuchen, ob es eine Assoziation zwischen den Erscheinungszeiräumen und den Bewertungen der Uder gibt. Ob User eher Bücher eines bestimmten Jahrzents  bewerten, oder ob es da keinen ZUsammenhang gibt.
